# 计算机系统基础

参考资料如下：

[操作系统的调度算法](https://juejin.cn/post/6869951514706722829)

[图解系统介绍 | 小林coding (xiaolincoding.com)](https://xiaolincoding.com/os/#%E5%B0%8F%E7%99%BD%E9%80%82%E5%90%88%E7%9C%8B%E5%90%97)

https://github.com/Hansimov/csapp

[CSAPP 笔记](https://hansimov.gitbook.io/csapp/part2/ch09-virtual-memory/9.8-memory-mapping)

# 计算操作系统

## CPU 速度

### Cache

Cache 的映像方式为组相联映像。

Cache 的速度远远高于内存（速度比基本上达到了1:100左右），由于速度差比较大，所以如果程序运行的cache 命中率较高的话其性能也会比较到。

比如，有一个 `int array[100]` 的数组，当载入 `array[0]` 时，由于这个数组元素的大小在内存只占 4 字节，不足 64 字节，CPU 就会**顺序加载**数组元素到 `array[15]`，意味着 `array[0]~array[15]` 数组元素都会被缓存在 CPU Cache 中了，因此当下次访问这些数组元素时，会直接从 CPU Cache 读取，提高了 CPU 读取数据的性能。

### 分支预测

TODO........

## 内存管理

### 核心点

在操作系统中有一个很核心的概念是虚拟化的概念，虚拟这个的意义是（虚拟：**向下屏蔽差异，向上提供统一的东西**），操作系统在其各个地方都使用了虚拟化的这种思想，比如在内存管理中有虚拟内存（其使用段页式来管理内存），在设备管理中有设备虚拟化。

### 虚拟内存

**虚拟内存的提出**

为了解决多进程可能会修改同一绝对地址的内容，会产生冲突。所以产生了虚拟地址的概念，即让操作系统为每个进程分配独立的一套虚拟地址。

**虚拟内存的作用**

- 虚拟内存可以使得进程对运行内存超过物理内存大小，程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

**虚拟内存的实现**

* 段式内存管理

* 页式内存管理

* 段页式内存管理

### 段式内存管理

一般程序会分若干个逻辑段例如C++程序分为 堆、栈、常量区、静态存储区、代码段 五个部分，所以操作系统会一次性将一整个段大小的内存分配给程序。

**虚拟地址映射为物理地址的方式如下：**

根据虚拟地址中的段号在段表中找到对应的项，获取段基址和段长，段内地址不超过段长时，物理地址 = 段基址+段内偏移 

![image-20240315223136243](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/image-20240315223136243.png)

**段式内存管理的缺点：**

* 造成大量的外部内存碎片。[内存碎片的概念解释](###内存碎片)

* 内存交换效率低：因为交换内存时需要**整块调出**再调入（即内存碎片整理，需要与磁盘交互）

**段式内存管理的好处：**

* 内存连续

* 需要多少就分配多少，没有内部内存碎片

### 页式内存管理

分页去解决分段管理虚拟内存的外部内存碎片和内存交换效率低的问题

**虚拟地址与逻辑地址的映射：**

1. 根据虚拟地址中存储的虚拟页号，找到对应的页表项

2. 根据页表项中存储的物理页号（可以计算出页基址）

3. 物理地址 = 页基址 + 页内偏移

![Image](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/v2-7879f9108d576b75dacb8ac2db434b60.png)

**好处：**

* 没有外碎片，内存利用率高。

* 程序不需要一整个调入内存，在做完映射之后，每次将所需的页调入即可。

* 内存交换快，因为每次发生缺页时只需将几个页调出交换即可。

**坏处：**

* 会产生内碎片，即使所需内存大小只有 1KB，我们也需要分一个页除去。

* 每个进程需要存储一个的虚拟页表，页表的存储需要巨大的空间

### 多级页表

不分级的情况下由于要保证页表覆盖整个虚拟空间（4GB），我们需要 1MB 个页表项

而分级后，对于没有使用到的一级页表，我们不需要给他分配二级页表空间，这样就节省了空间。

![Image](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/v2-2d9272654fa629060d7a57047753e5a3.png)

#### 程序局部性原理：

程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。

**缺点：**

多了几次转换过程，速度有所下降

**解决方案：**

根据程序局部性原理，我们用一个专门的 Cache 去存放常访问的页表项用于加速。

### 段页式内存管理

结合段式和页式的有点，将程序分为逻辑段，段内在按照固定块分。

![Image](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/v2-769d4187edca0d209681baa2fb1d1f27.png)

**虚拟地址**：段号+页号+页内偏移

我们需要三次寻址：

* 根据段号找到其对应的页表地址。

* 根据页号找到具体的页表项。

* 根据页表项的物理基址+页内偏移找到物理地址。

### malloc 如何分配内存

**通过两种方式来分配内存**：

* brk() : 直接将将堆顶指针往高地址移动，从而获得一块内存

brk 采用内存池去管理内存，内存池采用隐式链表去管理内存。

* mmap() : 从文件映射段中获取一块内存

mmap函数会在内存中找一段空白内存，然后将这部分内存与文件的内容对应起来。我们对内存的所有操作都会直接反应到文件中去。mmap的主要功能就是建立内存与文件这种对应关系。所以才被命名为memory map。

当分配的内存小于 128KB时，调用 brk，大于 128 KB 时调用 mmap。

> tip: 分配的是虚拟内存，没访问就不会分配物理内存

**free 释放内存：**

brk()： 就会缓存在内存池中

mmap(): 会直接还给操作系统

**只使用 mmap 的缺点：**

* 每次申请都要在内核态与用户态之间切换

* 每次释放后都还给操作系统，意味着每次申请时都会发生缺页（虚拟块号没对应的物理块号）

**只使用 brk 的缺点**：

在 malloc 和 free 的过程中会造成无法利用起来的内存碎片，造成内存泄漏。

> Tip：malloc 申请的内存前 16 个字节会记录相关信息。

### 内存满了会发生什么？

使用malloc 分配内存时，并没有真正的分配物理内存，而是我们去访问时，发生缺页中断，如果内存空间足够，直接从磁盘 swap 区调入，否则我们需要使用将一些页释放（LRU）

* 文件页：如果是干净的页，即数据已经同步到磁盘，那么直接释放，如果是脏页需要先如磁盘在清除

* 匿名页：通常是堆栈数据，我们需要将其保存到磁盘中（swap）

然后将物理内存与虚拟内存联系起来。

### 能不能申请 4GB 物理内存能不能申请 8 GB 虚存

- 在 32 位操作系统，因为进程理论上最大能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。
- 在 64位 位操作系统，因为进程理论上最大能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
  - 如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
  - 如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；

### 虚拟内存分区

![image-20240317112020165](.\assets\image-20240317112020165.png)

* 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小；

* 文件映射段，包括动态库、共享内存等，从低地址开始向上增长；

* 堆段，包括动态分配的内存，从低地址开始向上增长；

* BSS 段，包括未初始化的静态变量和全局变量；

* 数据段，包括已初始化的静态常量和全局变量；
- 代码段，包括二进制可执行代码；

**大端小端**

**大端法（Big-Endian）：**大端法是指数据的最高位字节（大端）存放在内存的最低位

**小端法（Little-Endian）：**小端法则相反，是将数据的最低位字节（小端）存放在内存的最低位。

## 进程管理

### 进程

以上是基本状态，但有时操作系统会把 不用的页挂起（放到磁盘中，等要用的时候在调入内存），所以得更正：

![Image](https://pic4.zhimg.com/80/v2-da40a900e9091c1d2e1a2bbe15e59c59.png)

#### PCB

**进程描述信息：**

- 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；
- 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；

**进程控制和管理信息：**

- 进程当前状态，如 new、ready、running、waiting 或 blocked 等；
- 进程优先级：进程抢占 CPU 时的优先级；

**资源分配清单：**

- 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。

**CPU 相关信息：**

- CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。

### 线程

线程控制块：记录线程状态信息（PC、栈指针、寄存器）

特点：

- 一个进程中可以同时存在多个线程；

- 各个线程之间可以并发执行；

- 各个线程之间可以共享地址空间和文件等资源；
* 线程只独享必不可少的资源，如寄存器和栈；

* 线程创建快，因为线程不涉及资源管理信息的分配

* 线程释放快，归还的信息少

* 同一个进程里的线程切换比进程切换快，因为共享虚拟内存

* 线程间交换数据不需要经过内核

**线程行下文切换**

- 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
- 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，**只需要切换线程的私有数据、寄存器等不共享的数据；**

**为什么线程崩溃会导致进程崩溃：**

这主要是因为在进程中，**各个线程的地址空间是共享的**，既然是共享，那么某个线程对地址的非法访问就会导致内存的不确定性，进而可能会影响到其他线程，这种操作是危险的，操作系统会认为这很可能导致一系列严重的后果，于是干脆让整个进程崩溃

### 进程线程的对比

**线程与进程的对比：**

- 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；
- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；
- 线程能减少并发执行的时间和空间开销；

### 调度

原则：

- **CPU 利用率**：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；
- **系统吞吐量**：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；
- **周转时间**：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；
- **等待时间**：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；
- **响应时间**：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。

#### 先来先服务

先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。

**特点**：长作业有利，短作业的周转时间长。

#### 短作业优先

优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。

**特点**：对长作业不利，可是产生“饿死”。

#### 高响应比优先调度算法 （ 理想模型）

每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行「响应比优先级」的计算公式：

![Image](https://pic4.zhimg.com/80/v2-5a52fb65cefd58951f8355f05aa31b5e.png)

**特点**：等待时间相同，短任务优先权高，服务时间相同，等待时间越长优先级越高。

#### 时间片轮转调度算法

每个进程被分配一个时间段，称为时间片（*Quantum*），即允许该进程在该时间段中运行。

**特点**：时间片太长，进程上下文切换频繁，耗时。时间片太长，短作业响应时间长。

#### 最高优先级调度算法

给每个进程设置优先级，优先级高的先执行

#### 多级反馈队列调度算法

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

![Image](https://pic4.zhimg.com/80/v2-7bc5e59f3e436dd9945b7a35429d56c1.png)

工作过程：

- 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
- 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
- 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

### 进程间通信

* 管道

* 消息队列

* 共享内存

* 信号量

* 信号

* Socket

进程用户地址独立，但是可以共用内核地址，所以进程间通信得通过内核。

#### 管道

**所谓的管道，就是内核里面的一串缓存**。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。

**特点**：效率低不适合频繁交换数据

#### 消息队列

A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。

**特点**：消息队列不适合比较大数据的传输。

#### 共享内存

**共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。

共享内存允许两个或多个进程共享一给定的存储区，因为数据不需要来回复制，所以是**最快的一种进程间通信机制**。共享内存可以通过mmap()映射普通文件（特殊情况下还可以采用匿名映射）机制实现，也可以通过系统V共享内存机制实现。**应用接口和原理很简单，内部机制复杂**。为了实现更安全通信，往往还**与信号灯等同步机制共同使用**。

#### 信号量

信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。

**特点**：核心是 P V 源语

### 多线程互斥如何处理

线程之间是可以共享进程的资源，比如代码段、堆空间、数据段、打开的文件等资源，但每个线程都有自己独立的栈空间。

多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为**临界区（*critical section*），它是访问共享资源的代码片段，一定不能给多线程同时执行。**

同步与互斥概念不同:

* 同步：强调两者协调关系，执行分先后。

* 互斥：强调不同时执行，谁先谁后无所谓。

#### 同步与互斥的实现

- **锁**：**加锁、解锁操作**, 任何想进入临界区的线程，必须给临界区加锁，若成功则进入访问。访问完成时解锁。
- **信号量**：P、V 操作；

#### 锁

* **忙等待锁**：当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为**自旋锁（*spin lock*）**。

* **无等待锁**：例如**互斥锁**，当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。

#### 信号量

**互斥**：信号量设置1就行

**同步**：

* 生产者消费者：访问缓冲器时互斥，生产完产品后需要同步

* 哲学家就差问题 ：五根筷子，五个哲学家、只有拿了两个筷子才能吃饭。
  
  * 一次只让一个哲学家能
  
  * 偶数编号哲学家拿筷子顺序：先左再右，奇数号哲学家：先右再左（例如 一号会和二号抢筷子，没抢到的就被阻塞，这样 5 根筷子，4个哲学家无论如何，都能有一个人拿到筷子。准确说有一半人能吃上饭）
  
  * 划分状态：思考、饥饿、进餐，只有左右邻居都没进餐时，我才进餐。

* 读者-写者问题：
  
  - 「读-读」允许：同一时刻，允许多个读者同时读
  - 「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写
  - 「写-写」互斥：没有其他写者时，写者才能写

### 死锁

**死锁条件：**

* **资源互斥**：资源有限，不允许同时使用

* **保持与等待**：拿到资源后，不会主动释放

* **不可剥夺**：在资源使用完之前，不允许别的线程访问。

* **环路等待**：两个线程获取资源的顺序构成了环形链。
  ![Image](https://pic4.zhimg.com/80/v2-929cab70695343c9c31907582c01c79e.png)

**如何避免死锁**

1. 给资源设置访问顺序，要求只能按照既定顺序获取资源

2. 要么全拿，要么一个不拿

## 磁盘调度

* 先来先服务

* 最短寻道时间优先：每次选择请求地址离磁头最近的那个

* 扫描：没访问到头不允许转向，会按 **左-中-右-中-左** 顺序响应

* 循环扫描：回程时不响应请求，即 **左-中-右 - 左-中-右**
  
  * **优化**：磁头在移动到「最远的请求」位置，然后立即反向移动。

# 计算机网络

## 网络体系结构

应用层，表示层，会话层，传输层，网络层，数据链路层，物理层

![image-20240315142055401](E:\WorkPr\知识点复习\复习内容\assets\image-20240315142055401.png)

* 应用层 (Application):

我们电脑或手机使用的应用软件都是在应用层实现。那么，当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。所以，应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP等。

*对于 TCP/IP 协议中应用层对应了IOS 的应用层，表示层，会话层*

* 表示层(Presentation Layer):

数据的表示、安全、压缩。(在五层模型里面已经合并到了应用层)

* 会话层(Session Layer):

建立、管理、终止会话。(在五层模型里面已经合并到了应用层)对应主机进程，指本地主机与远程主机正在进行的会话

* 传输层 (Transport):

两个传输协议，分别是 TCP 和 UDP。（后续会详细介绍）

UDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。

TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。

* 网络层 (Network):

网络层最常使用的是 IP 协议，IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过规定就会**再次进行分片**，得到一个即将发送到网络的 IP 报文。

![image-20240315142041038](E:\WorkPr\知识点复习\复习内容\assets\image-20240315142041038.png)

* 数据链路层 (Link):

建立逻辑连接、进行硬件地址寻址、差错效验等功能。(由底层网络定义协议)。将比特组合成字节进而组合成帧，用MAC地址访问介质，错误发现但不能纠正。

* 物理层(Physical Layer):

建立、维护、断开物理连接。(由底层网络定义协议)

## TCP 协议

### **TCP 协议简介**

TCP 是**面向连接的**（一定是「一对一」才能连接）、**可靠的**（TCP 都可以保证一个报文一定能够到达接收端）、**基于字节流**（消息会被系统分成多个的 TCP 报文，如果接收方不知道消息的边界，无法读出一个有效的用户消息的，当上一个TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，也不能去处理）的传输层通信协议。

![image-20240315142023516](E:\WorkPr\知识点复习\复习内容\assets\image-20240315142023516.png)

### **TCP 头部格式的详细说明**

序列号：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。

确认应答号：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。

控制位：

- *ACK*：该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。
- *RST*：该位为 `1` 时，表示 TCP 连接中出现异常必须强制断开连接。
- *SYN*：该位为 `1` 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
- *FIN*：该位为 `1` 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段。

### **TCP 三次握手建立连接**

![image-20240315142004309](E:\WorkPr\知识点复习\复习内容\assets\image-20240315142004309.png)

TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而建立连接是通过三次握手来进行的

一开始，客户端和服务端都处于 `CLOSE` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态

* 第一次握手

客户端会随机初始化序号（`client_isn`），同时把 `SYN` 标志位置为 `1`。

接着把第一个报文发送给服务端，表示向服务端发起连接，**该报文用于确认客户端可以正常发送信息到服务端。**

* 第二次握手

服务端收到客户端的报文后，服务端也随机初始化自己的序号（`server_isn`），确认应答号字段填入刚刚接受到的序列号+1即 `client_isn + 1`, 并把把 `SYN` 和 `ACK` 标志位置为 `1`。

**该报文用于确认服务端可以正常发送信息到客户端。**

* 第三次握手

客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，将确认应答号填入 `server_isn + 1` ，最后把报文发送给服务端。

**这次报文可以携带客户到服务端的数据，表示TCP 传输字节流的开始**

### **TCP 的握手为什么是三次，而不是四次或者两次？**

* 为什么不是四次？

三次握手已经可以建立稳定的连接，为防止消耗过多资源所以选择三次

* 为什么不是两次？

在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接。

![image-20240315144729525](E:\WorkPr\知识点复习\复习内容\assets\image-20240315144729525.png)

### TCP 四次挥手断开连接

![image-20240315145031812](E:\WorkPr\知识点复习\复习内容\assets\image-20240315145031812.png)

* 第一次挥手

客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文。

**第一次挥手代表客户端向服务器发送断开连接请求**

* 第二次挥手

服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入关闭等待状态。但仍会向客户端发送信息。

**第二次挥手代表服务端收到断开连接请求，并向客户端发送**

* 第三次挥手

等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。

**第三次挥手代表服务端处理完全部的数据**

* 第四次挥手

客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态

## UDP 协议

### UDP 概念

提供不可靠的服务并且是无连接的

- 无连接：在传输数据前不需要建立连接，也避免了后续断开连接的操作
- 不重新排序：对到达顺序混乱的数据包不进行重新排序。
- 没有确认：发送数据包无须等待对方确认，因此使用UDP协议可以随时发送数据，但无法保证数据能否成功呗目标主机接受
- 分组首部开销小，TCP首部20字节，UDP首部8字节
- UDP没有拥塞控制，应用层能够更好的控制要求发送的数据和发送时间，网络中拥塞控制不会影响主机的发送速率。有些实时应用要求以稳定的速度发送，能容忍一些数据的丢失，但是不能允许较大的时延，如视频直播
- UDP提供尽最大努力的交付，不保证可靠交付。所有维护传输可靠性的工作需要用户在应用层来完成，没有TCP的确认机制、重传机制。如果因为网络原因没有传送到对端，UDP不会个应用返回错误信息
- UDP数据报是有长度的，每个UDP数据报都有长度，如果一个数据报正确地到达目的地，那么改数据报的长度将随数据一起传递给接收方，而TCP是一个字节流协议，没有任何协议上的记录边界
- UDP支持多播和广播
- UDP是面向报文的，对应用层交下来的报文，增加首部后直接向下交付为IP层，既不合并，也不拆分，保留这些报文的边界；对IP层交上来的UDP用户数据，在去除首部后就原封不动地交付给上层应用进程，报文不可分割，是UDP数据报处理的最小单位；因为这样UDP不够灵活，不能控制读写数据的次数和数量

![UDP 头部格式](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230439961.png)

### UDP 实现可靠传输：

通过在传输层的上层增加一些机制来实现。

应用层确认机制：在应用层上，可以实现自定义的确认机制。发送方在发送数据后等待接收方的确认消息，如果在一定时间内未收到确认，则重新发送数据。这样可以确保数据的可靠传输。

数据校验和重传：在UDP数据包中添加校验和字段，接收方在接收数据时计算校验和并与发送方的校验和进行比较。如果不匹配，则要求发送方重新发送数据。

## UDP 与 TCP 的区别

**TCP 和 UDP 区别：**

*1. 连接*

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

*2. 服务对象*

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、一对多、多对多的交互通信

*3. 可靠性*

- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。

*4. 拥塞控制、流量控制*

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

*5. 首部开销*

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

*6. 传输方式*

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

# 编译原理

[高级语言的编译](https://tech.meituan.com/2015/01/22/linker.html)

**对于声明与定义来说**

```C++
0000000000000000 D g_a
0000000000000004 C g_b
0000000000000000 b g_c
                 U g_x
```

对于声明来说，没有真正的内存空间但会将其分配为符号为 U 的段中，而定义会分配地址。

```C++
int g_a = 1;            //定义有初始值全局变量
int g_b;                //定义无初始值全局变量
static int g_c;         //定义全局static变量
extern int g_x;         //声明全局变量
```

对于函数来讲他会编译成这样，调用动态链接库中函数的话会在调用点处寻找目标Dll 的目标函数，找到之后，链接库首先会把这个动态链接库写到可执行文件的依赖库中，并生成代理符号，以后调用通过代理符号。

```C++
00000000004005b4 T main
                 U printf@@GLIBC_2.2.5
                 U strncpy@@GLIBC_2.2.5
```

一段程序会被编译成这样，当我们调用dll 或者静态链接库（动态链接库的时候）

# 关键词说明

### 内存碎片

内存碎片主要分为，内部内存碎片和外部内存碎片。

1. 内部内存碎片：当内存分配时，如果分配的内存块大于请求的内存大小，多出来的部分就会成为内部内存碎片。这部分内存虽然没有被使用，但却不能被其他程序使用，从而造成了内存的浪费。
2. 外部内存碎片：外部内存碎片是指已经分配给程序使用的内存区域中，有些空闲的小块内存无法利用起来，因为它们太小，无法满足程序的大内存需求。这些不连续且分散的空闲内存块形成了外部内存碎片。

外部内存碎片的避免方式是内存的交换，通过内存的交换将原先的内存空隙填满。

内部内存的碎片的方法

段式管理会出现外部内存碎片。
