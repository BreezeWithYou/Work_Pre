# 操作系统复习知识整理

# 进程

## 进程的概念

关系概述

* 程序不能独立运行。只能作为进程执行。程序是静态的，进程是动态的。
* 程序有两种执行方式：程序的顺序执行和程序的并发执行。并发执行通过多进程实现

### 进程的定义

- 操作系统用来实现程序**并发**执行的实体。

首先在这里要了解并发和并行。并发指的是一个处理器同时处理多个任务。并行是指多个处理器或者是多核的处理器同时处理多个不同的任务

- 作为操作系统**资源分配**和**独立运行**的基本单位。

进程是有自己独立的资源这点体现在页表，有自己的资源上面

## 进程的内存相关

### 进程的内存空间

![image-20240317112020165](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/image-20240317112020165.png)



* 内核空间

每个进程可以通过系统调用陷入内核态，因此内核空间是由所有进程共享的。

* 进程栈

进程栈的初始化大小是由编译器和链接器计算出来的，但是栈的实时大小并不是固定的，Linux 内核会根据入栈情况对栈区进行动态增长（其实也就是添加新的页表）。但是并不是说栈区可以无限增长，它也有最大限制 RLIMIT_STACK (一般为 8M)

进程栈的地址增长方式

进程在运行的过程中，通过不断向栈区压入数据，当超出栈区容量时，就会耗尽栈所对应的内存区域，这将触发一个 缺页异常 (page fault)。通过异常陷入内核态后，异常会被内核的 expand_stack() 函数处理，进而调用 acct_stack_growth() 来检查是否还有合适的地方用于栈的增长。

如果栈的大小低于 RLIMIT_STACK（通常为8MB），那么一般情况下栈会被加长，程序继续执行，感觉不到发生了什么事情，这是一种将栈扩展到所需大小的常规机制。然而，如果达到了最大栈空间的大小，就会发生 栈溢出（stack overflow），进程将会收到内核发出的 段错误（segmentation fault） 信号。（动态栈增长是唯一一种访问未映射内存区域而被允许的情形，其他任何对未映射内存区域的访问都会触发页错误，从而导致段错误。一些被映射的区域是只读的，因此企图写这些区域也会导致段错误。）

* 文件映射区

mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现**文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映**。

实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。如下图所示：

同时再说明一下 mmap 函数的实现：

1. 进程启动mmap 过程，并在虚拟地址空间中为映射创建虚拟映射区域（主要是数据结构）
2. 调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系
3. 进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝

文件映射区的优势：

- **文件 I/O：** 提高对文件的读写性能，正常的读文件使用 `readfile` ，操作系统有页缓存机制会将数据先读到内核空间的内存中。然后再读到内存中，存在两次拷贝。
- **共享内存：** 进程间通信的一种方式，多个进程可以映射同一个文件，实现进程通信。
- **实现类似 `malloc` 和 `free` 的内存管理机制：** 通过内存映射技术，实现 malloc 内存回收。

详细内容参考：[mmap 的实现](https://www.cnblogs.com/huxiao-tee/p/4660352.html)

## 进程的同步与通信

### 进程的同步和通信的概念

**进程同步和进程通信的区别**

主要的区别在于：进程同步控制多个进程按一定顺序执行；进程通信，实现进程间信息交换。目标是不一样的。

进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

**临界资源和临界区**

- 共享的互斥资源称为**临界资源**。
- 对临界资源进行访问的那段代码称为**临界区**。
- 为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

### 进程的同步

#### 锁同步

锁有很多种类还是从基本的锁 ` metux` （互斥锁）来说。

**锁的同步从逻辑上的原理来说：**

是用一个变量来代表临界资源的状态，称之为锁。通常用“0”代表资源可用，相当于锁打开，用“1”代表资源已被占用，相当于锁闭合。

**锁的同步从实现上的原理来说：**

锁分为加锁和解锁两个命令，这两个命令一定是成对出现的，加锁之后一定要解锁，否则可能会造成死锁。锁通过加锁和解锁可以保证并发编程的三个特性的，下面我们来看看是如何实现的。

1. 线程加锁时，会强制把线程的本地变量设置为无效，使被监视器保护的临界区代码必须要从主内存中去读取共享变量，让cpu的缓存和主内存保持一致。这个是通过**读内存屏障(Load Memory Barrier)**来实现的
2. 加锁后在指令执行期间该缓存行会一直被锁定，其它处理器无法读/写该指令要访问的内存区域，因此能保证指令执行的原子性。这个操作过程叫做缓存锁定
3. 被加锁的指令的前面和后面的指令都被禁止重排序，即前面的指令不能被重排序到后面，后面的指令不能被重排序到前面，保证了指令的有序性
4. 线程解锁时，会强制把cpu缓存中的最新数据更新写入到主内存中，让其他线程可见，保证了指令的可见性，这个是通过**写内存屏障(Store Memory Barrier)**来实现的

#### 信号量

信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。如果信号量的取值只能为 0 或者 1，那么就成为了 **互斥量（Mutex）** 。

#### 条件变量

以管道程序为例子

管程相当于一个隔离区，所有进入管程要访问临界区资源时，必须经过管程才能进入，管程每次只允许一个进程进入。若采用忙等待的方式，则容易引发死锁，因此引入了条件变量`CV`。一个条件变量CV可理解为一个进程的等待队列，队列中的进程正等待某个条件Cond变为真。每个条件变量关联着一个条件，如果条件Cond不为真，则进程需要等待，如果条件Cond为真，则进程可以进一步在管程中执行。

#### 经典的同步问题

- 生产者消费者问题

使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

```C++
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

- 哲学家进餐问题

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

```c++
#define N 5
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think(i);
        take_two(i);
        eat(i);
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    check(i);
    up(&mutex);
    down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}
```

// todo 管程的介绍

### 进程的通信

管道文件通信机制

- PIPE匿名管道
- FIFO命名管道
- 高级管道通信

消息传递通信机制

- 消息队列

共享内存通信机制

* 共享内存。（可以通过信号量控制）

基础进程通信机制。只能传递状态和整数值（控制信息）

- 锁、信号量、条件变量
- 信号signal wait notify

网络进程通信机制。主要是通过socket实现的tcp或者是udp通信。可以实现不同主机进程的通信

- socket  网络通信

#### 管道文件通信

**所谓的管道，就是内核里面的一串缓存**。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。

**特点**：

* 效率低不适合频繁交换数据
* 管道通讯有很多都是单向或者半双工的
* 管道通信只有在对方接收之后才可以返回

#### 消息队列

A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。

主要利用的数据结构是消息缓冲区

**特点**：

* 可以双向传输

* 通过消息队列可以实现异步通信，不需要等待。
* 消息队列的消息长度有限制，一般不能超过系统限制的最大值。
* 消息队列需要调用特殊的系统调用来读写消息，开销较大。

#### 共享内存

**共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。

共享内存允许两个或多个进程共享一给定的存储区，因为数据不需要来回复制，所以是**最快的一种进程间通信机制**。共享内存可以通过mmap()映射普通文件（特殊情况下还可以采用匿名映射）机制实现，也可以通过系统V共享内存机制实现。**应用接口和原理很简单，内部机制复杂**。为了实现更安全通信，往往还**与信号灯等同步机制共同使用**。

#### 信号量

信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。

**特点**：核心是 P V 源语

# 线程

## 线程的概念

线程是**独立调度的基本单位**。一个进程中可以有多个线程，它们共享进程资源。线程栈是在进程的堆中分配栈空间，每个线程拥有独立的栈空间，为了避免线程之间的栈空间踩踏，线程栈之间还会有以小块guardsize用来隔离保护各自的栈空间，一旦另一个线程踏入到这个隔离区，就会引发段错误。

### 线程与进程的区别

* 资源与系统调度。线程是独立调度的基本单位，进程是资源分配的基本单位。在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

* 并发性。线程使得操作系统具有更好的并发性，从而能更加有效地提高系统资源的利用率和系统的吞吐量。

* 系统开销。由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

* 通信方面。线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助IPC。

## 线程与进程适用的场景

浏览器来讲其页面是多进程还是多线程的：答案是多进程，各个页面之间并不需要进行多频繁的通信，但是在同一网页界面可能会拥有多个线程去协助执行，比如网络线程，视频解码线程，渲染线程等。

### 协程相对于进程的优点

1. 最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。
2. 第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。
3. 因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。

## 死锁

**死锁条件：**

* **资源互斥**：资源有限，不允许同时使用

* **保持与等待**：拿到资源后，不会主动释放

* **不可剥夺**：在资源使用完之前，不允许别的线程访问。

* **环路等待**：两个线程获取资源的顺序构成了环形链。
  ![Image](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/v2-929cab70695343c9c31907582c01c79e.png)

**如何避免死锁**

* 给资源设置访问顺序，要求只能按照既定顺序获取资源

* 要么全拿，要么一个不拿

* 银行家算法

当进程请求一组资源时，系统必须首先确定是否有足够的资源分配给该进程。若有，在进一步的检测将这些资源分配给进程后，是否会是系统处于不安全状态；如果不会，才将资源分配给该进程，否则让进程等待。

# 程序执行的步骤

1. 首先是要**编译**，由编译程序(Compiler)将用户源代码编译成若干个目标模块(Object Module)；
2. 其次是**链接**，由链接程序(Linker)将编译后形成的一组目标模块，以及它们所需要的库函数链接在一起，形成一个完整的装入模块(Load Module)；
3. 最后是**装入**，由装入程序(Loader)将装入模块装入内存。然后执行

![image-20240728012142655](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/image-20240728012142655.png)

## 装入

### 逻辑地址（相对地址）

从0开始编号，在编译生成可执行文件的时候确定。包括以下两种形式：

- 一维逻辑地址（地址）
- 二维逻辑地址（段号：段内地址）

### 物理地址（绝对地址）

程序执行所使用的主存地址空间。处理器执行指令时按照物理地址进行

### 地址转换（重定位）

把逻辑地址转换成物理地址。包括两种方式：

- 静态重定位：在程序装入内存时进行地址转换。由装入程序执行，早期小型OS使用
- 动态重定位：在CPU执行程序时进行地址转换。从效率出发，依赖硬件地址转换机构

### 分类

根据地址转换的方式，可以将程序的装入分为三种方式。

1. **绝对装入方式**。在编译时，如果知道程序将驻留在内存的什么位置，那么，编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。装入模块被装入内存后，由于程序中的逻辑地址与实际内存地址完全相同，故不须对程序和数据的地址进行修改。程序中所使用的绝对地址，既可在编译或汇编时给出，也可由程序员直接赋予。
2. **静态重定位装入方式**。在装入时对目标程序中指令和数据的修改过程称为重定位。又因为地址变换通常是在装入时一次完成的，以后不再改变，故称为静态重定位。
3. **动态重定位装入方式**。动态运行时的装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址都仍是相对地址。需要一个重定位寄存器的支持。

## 链接

### 编译系统


* 以下是一个 hello.c 程序：

```c
#include <stdio.h>

int main()
{
    printf("hello, world\n");
    return 0;
}
```

* 在 Unix 系统上，由编译器把源文件转换为目标文件。

```bash
gcc -o hello hello.c
```
![image-20240728012336826](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/image-20240728012336826.png)

1. 预处理阶段：处理以 # 开头的预处理命令；
1. 编译阶段：翻译成汇编文件；
1. 汇编阶段：将汇编文件翻译成**可重定位目标文件**；
2. 链接阶段：将可重定位目标文件和printf.o 等单独预编译好的目标文件进行合并，得到最终的**可执行目标文件**。

### 目标文件

- **可执行目标文件**：可以直接在内存中执行；
- **可重定位目标文件**：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件；
- **共享目标文件**：这是一种特殊的可重定位目标文件，可以在运行时被动态加载进内存并链接；


### 分类

* 源程序经过编译后，可得到一组目标模块，再利用链接程序将这组目标模块链接，形成装入模块。根据链接时间的不同，可把链接分成如下三种：
  1. 静态链接。在程序运行之前，先将各目标模块及它们所需的库函数，链接成一个完整的装配模块，以后不再拆开。我们把这种事先进行链接的方式称为静态链接方式。
  2. 装入时动态链接。这是指将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的链接方式。
  3. 运行时动态链接。这是指对某些目标模块的链接，是在程序执行中需要该(目标)模块时，才对它进行的链接。

### 静态链接

静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：
1. 符号解析：符号解析的目的是将每个符号引用与一个符号定义关联起来。每个符号对应于一个函数、一个全局变量或一个静态变量。
2. 重定位：链接器通过把每个符号定义与一个内存位置关联起来。然后修改所有对这些符号的引用，使得它们指向这个内存位置。

本质上链接器将每一个符号和对应位置的函数地址的内存位置相关联。

### 动态链接

静态库有以下两个问题：
- 当静态库更新时那么整个程序都要重新进行链接；
- 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。

动态链接的方式在.exe 文件中存储了函数的入口地址，函数体具体由进程空间的dll 提供，当我们去修改一个函数的时候往往只需要更新dll 而不需要更新其 .exe 文件。同时以游戏引擎举例，游戏引擎中每一个模块都是一个dll 我们每次更新仅仅只需要更新变动模块的dll 即可。在大型游戏的开发系统中，常常会将各个模块编写成一个个dll 文件没有变动的地方就不需要重新编译。

# 内存管理

## 虚拟内存管理

### 核心点

在操作系统中有一个很核心的概念是虚拟化的概念，虚拟这个的意义是（虚拟：**向下屏蔽差异，向上提供统一的东西**），操作系统在其各个地方都使用了虚拟化的这种思想，比如在内存管理中有虚拟内存（其使用段页式来管理内存），在设备管理中有设备虚拟化。

### 虚拟内存

**虚拟内存的提出**

为了解决多进程可能会修改同一绝对地址的内容，会产生冲突。所以产生了虚拟地址的概念，即让操作系统为每个进程分配独立的一套虚拟地址。

**虚拟内存的作用**

- 虚拟内存可以使得进程对运行内存超过物理内存大小，程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

**虚拟内存的实现**

* 段式内存管理

* 页式内存管理

* 段页式内存管理

### 段式内存管理

一般程序会分若干个逻辑段例如C++程序分为 堆、栈、常量区、静态存储区、代码段 五个部分，所以操作系统会一次性将一整个段大小的内存分配给程序。

**虚拟地址映射为物理地址的方式如下：**

根据虚拟地址中的段号在段表中找到对应的项，获取段基址和段长，段内地址不超过段长时，物理地址 = 段基址+段内偏移 

![image-20240315223136243](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/image-20240315223136243.png)

**段式内存管理的好处：**

* 内存连续

* 需要多少就分配多少，没有内部内存碎片

**段式内存管理的缺点：**

* 内存映射仍然是以程序为单位，当内存不足是时仍然需要将整个程序交换到磁盘，内存的使用效率依然很低。

* （由于存在大量外部内存碎片）即当某个进程需要一块比较大的内存空间是，若物理地址没有连续的这么一块（即便其有很多块较小的，加起来也很大），在分段机制下，该进程是无法运行的。

### 页式内存管理

分页机制本质：将大小不同的大内存段拆分成大小相等的小内存块，可以提供虚拟的连续内存空间，映射到可以不连续到物理内存，让进程能够运行在不连续到物理空间。解决了上述段式内存管理的问题的问题看。

**虚拟地址与逻辑地址的映射：**

1. 根据虚拟地址中存储的虚拟页号，找到对应的页表项

2. 根据页表项中存储的物理页号（可以计算出页基址）

3. 物理地址 = 页基址 + 页内偏移

![Image](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/v2-7879f9108d576b75dacb8ac2db434b60.png)

**好处：**

* 没有外碎片，内存利用率高。

* 程序不需要一整个调入内存，在做完映射之后，每次将所需的页调入即可。

* 内存交换快，因为每次发生缺页时只需将几个页调出交换即可。

**坏处：**

* 会产生内碎片，即使所需内存大小只有 1KB，我们也需要分一个页除去。

* 每个进程需要存储一个的虚拟页表，页表的存储需要巨大的空间

### 多级页表

不分级的情况下由于要保证页表覆盖整个虚拟空间（4GB），我们需要 1MB 个页表项

而分级后，对于没有使用到的一级页表，我们不需要给他分配二级页表空间，这样就节省了空间。

![Image](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/v2-2d9272654fa629060d7a57047753e5a3.png)

#### 程序局部性原理：

程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。

**缺点：**

多了几次转换过程，速度有所下降

**解决方案：**

根据程序局部性原理，我们用一个专门的 Cache 去存放常访问的页表项用于加速。

### 段页式内存管理

结合段式和页式的有点，将程序分为逻辑段，段内在按照固定块分。

![Image](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/v2-769d4187edca0d209681baa2fb1d1f27.png)

**虚拟地址**：段号+页号+页内偏移

我们需要三次寻址：

* 根据段号找到其对应的页表地址。

* 根据页号找到具体的页表项。

* 根据页表项的物理基址+页内偏移找到物理地址。

## 页面置换算法

### 最优替换算法OPT, Optimal replacement algorithm

1. 所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。
2. 是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。
3. 举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

```html
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
```

4. 开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

### 先进先出FIFO First In First Out

1. 总是淘汰最先调入主存的那一页，或者说主存驻留时间最长的那一页（常驻的除外）
2. 选择换出的页面是最先进入的页面。该算法会将那些经常被访问的页面换出，导致缺页率升高。
3. 模拟的是程序执行的顺序性，有一定合理性

### 最近最少用LRU，Least Recently Used

1. 为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。
2. 因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

```
4，7，0，7，1，0，1，2，1，2，6
```