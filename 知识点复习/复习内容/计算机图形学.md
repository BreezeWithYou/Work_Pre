## 渲染管线学习

### 图形渲染管线

![2.2](https://pic4.zhimg.com/80/v2-2f9d77052843970951fec3ad99ccc661.png)

![](https://pic1.zhimg.com/v2-85a9e77245f43d4bab56f2052c3d81f0_r.jpg)

**CPU 端的应用阶段**，可见性判断（视椎体剔除）、设置渲染状态（控制着色器参数，使用的纹理，材质）。渲染需求以DrawCall 的形式从CPU发起进入下一阶段GPU。

**几何阶段包括，顶点相关着色器、裁剪和屏幕映射阶段：**

**顶点相关着色器：**

顶点着色器：顶点着色器的主要任务是点变为裁剪空间，同时也可以连带着输出颜色，纹理uv。之后会在光珊时之后进行顶点属性插值（重心坐标），投影变换主要就是MVP矩阵。

曲线细分着色器：之后会有曲线细分用于细化靠近的细节

几何着色器：特点用于生成顶点，比如草地的渲染。

*此时顶点坐标从模型空间到齐次裁剪空间（经过MVP 变换），经过硬件的透视除法变为NDC空间。*

**裁剪**：对于在后续渲染阶段不需要的信息(裁剪对部分不在视体内部的图元进行裁剪，对于不在视椎体中的三角形完全剔除，对于一部分在视椎体中的三角形裁掉在外面的那一部分。)

**屏幕映射阶段**：主要目的是将之前步骤得到的坐标映射到对应的屏幕坐标系上

*此时到了屏幕空间*

**光栅化阶段[光栅化算法详解](###光栅化算法详解)，包含三角形设置和三角形遍历阶段。**

此时三角形顶点信息变换到屏幕空间，需要通过已知的三角形顶点求出三角形内部所有点的信息。找到哪些像素被三角形所覆盖，决定是否要生成片段。

三角形设置：计算出三角形的一些重要数据(如三条边的方程、深度值等)以供三角形遍历阶段使用，这些数据同样可用于各种着色数据的插值。

三角形遍历：找到哪些像素被三角形所覆盖，并对这些像素的属性值进行插值。通过判断像素的中心采样点是否被三角形覆盖来决定该像素是否要生成片段。通过三角形三个顶点的属性数据，插值得到每个像素的属性值。此外透视校正插值也在这个阶段执行。

**像素处理阶段，包括像素着 色和合并**

进行光照计算和阴影处理，决定屏幕像素的最终颜色。

合并，包括各种测试和混合操作，如透明测试、模板测试、深度测试以及色彩混合等。经过了测试合并阶段，并存到帧缓冲的像素值，才是最终呈现在屏幕上的图像。

## DX12 渲染流水线

**CPU 端：**

使用Pipeline State Object（PSO）完成整个管线的配置（shader及一些固定管线的设定）；调用 CommandList 绘制场景中的几何体。

**几何阶段：**

**顶点着色器**

从显存中读取几何数据（索引和顶点），并装配为几何图元。顶点着色器的主要任务是点从模型空间乘上MVP 变换到裁剪空间，同时也可以连带着输出颜色，纹理uv。之后会在光珊时之后进行顶点属性插值（重心坐标），投影变换主要就是MVP矩阵。

**曲线细分阶段**

利用镶嵌化处理技术对网格中的三角形进行细分来增加物体表面的三角形数量。再将这些三角形偏移到合适的位置增加网格细节。

**几何处理阶段**

几何处理阶段接受完整的图元，并可在此阶段创建和销毁几何体，比如草地的渲染中，我们接受简单的顶点信息，生成草的。同时也可以将生成的结点通过流输出阶段到显存中的一块缓冲区。

**裁剪阶段**

裁剪阶段主要是将视椎体外面的图元信息进行裁剪，（裁剪操作完成之后会进行透视除法，将其转到NDC 空间）

#### 光栅化阶段：

**视口变换**

视口变换主要是将NDC空间变换为视口空间（二维空间）

**背面剔除**

通过叉乘计算法向量，通过法向量判断三角形的朝向，对于背对我们的三角形进行剔除操作。

**顶点属性插值**

使用重心坐标进行三角形属性的插值。

#### 像素着色阶段

**像素着色阶段**

使用像素着色器进行像素着色，进行光照计算和阴影处理，决定屏幕像素的最终颜色。

**合并输出阶段**

合并，包括各种测试和混合操作，如透明测试、模板测试、深度测试以及色彩混合等。经过了测试合并阶段，并存到帧缓冲的像素值，才是最终呈现在屏幕上的图像。

### MVP 变换

MVP 变换主要是 Model ，View，Project 矩阵三者

`Model` 矩阵

```C++
worldMatrix = scaleMatrix * rotationMatrix * translationMatrix;
```

`View` 矩阵

`Project`变换：

投影矩阵主要使用的是 `XMMatrixPerspectiveFovLH`

```C++
XMMatrixPerspectiveFovLH(FOV, Ratio(距离), m_zNear(近平面距离), m_zFar(远平面距离));
```

![QQ图片20240325151601](https://gitee.com/li-jiaqin-2022/pircture-all/raw/master/QQ图片20240325151601.jpg)

**透视除法**

对于透视除法的理解，在经过P 投影矩阵之后会到一个齐次裁剪空间，转变为NDC 空间。在齐次裁剪空间中的进平面的点的坐标都是 Near ,远平面都是 far （如果有一个远平面有一个物体，那他看起来还是和进平面的大小差不多）而透视除法之后，远平面的物体的大小明显减少。透视除法，是对于真实世界近大远小的一种修正

参考资料：[计算机图形学 - MVP 矩阵的推导_mvp矩阵推导-CSDN博客](https://blog.csdn.net/G0rgeoustray/article/details/118712283)          [MVP 矩阵推导](https://zhuanlan.zhihu.com/p/144329075)

#### 透视除法详解

**透视除法(perspective division)**。第四个分量 W 来自于观察空间的Z，接下来就是用齐次坐标系的 W 分量去除以x、y、z分量。使用透视除法消除齐次坐标的影响。

经过这一步， 我们可以把坐标从**齐次裁剪坐标空间**转换到 **NDC 标准化设备坐标** 中。经过透视投影变换后的裁剪空间，经过齐次除法后会变换到一个立方体内。按照 **OpenGL** 的传统，这个立方体的X、Y、Z分量的范围都是[-1, 1]。但在 **DirectX** 这样的API中，Z分量的范围会是[0, 1]。

### 光栅化算法详解

**方法：扫描线方法（Line sweeping）**

之前我在在 tinyrenderer 这个开源项目中的使用的CPU 画线方法，适合cpu单线程计算。

给定两个坐标：坐标1`(x0,y0)` ，坐标2`(x1,y1)`。

```C++
void line(int x0, int y0, int x1, int y1, TGAImage& image, TGAColor color) {
    for (int x = x0; x <= x1; x++) {
        float t = (x - x0) / (float)(x1 - x0);
        int y = y0 * (1 - t) + y1 * t;
        image.set(x, y, color);
    }
}
```

![本图说明了](https://pic4.zhimg.com/80/v2-da03a9398f3fe8e3d7ff04535d339ae8.jpg)

**方法二：三角形叉乘法**

* 首先构造出三角形的最大外接矩形，即AABB 包围核。
* 遍历包围盒每个像素，分别判断是否属于三角形。
* 逐个进行计算。

![e7458c2e6823b23ecd40bba89639d0a3](E:\WorkPr\知识点复习\复习内容\assets\e7458c2e6823b23ecd40bba89639d0a3.jpg)

由于屏幕空间是2维的因此叉乘之后判断符号即可，核心是不管顺时针还是逆时针判断这三个叉乘结果是否一致。

**方法三：三角形重心坐标插值**
$$
P = \alpha A+ \beta B+\gamma C
$$

$$
\alpha = S_{pbc}/S_{abc}
$$

$$
\beta = S_{pac}/S_{abc}
$$

$$
\gamma = 1 -\alpha + \beta
$$

判断三个参数在`（0,1）`之间。

### 渲染管线优化

**Early - Z**

**管线位置**：位于片元着色之前，光栅化之后；Early-Z 是基于硬件的优化，满足条件会自动开启；在计算片元之前，做一次**深度测试**，如果不通过就直接丢弃，避免一些重复的计算；

传统的深度测试在计算片元之后，导致有些片元计算了之后并没有通过深度测试，被直接抛弃了，这就等于白计算了，非常浪费。所以区分于**传统的深度测试**（ZTest），硬件自动做了一步**提前的深度测试**（ZCull），叫作 Early-Z；

**Early - Z 失效的情况**（三种）

* 开启 AlphaTest、手动丢弃片元、手动修改 GPU 插值得到的深度；

Early - Z 不止会进行**深度测试**，通常还会开启**深度写入**；前面渲染的片元被丢弃，但是写入了深度，遮挡导致后续的像素就无法正常渲染了；

* 开启 Alpha Blend；

开启 **Alhpa Blend** 需要**关闭深度写入**，所以就无法进行 Early - Z；

* 关闭深度测试

无法进行深度测试；

## 三维数学

### 基础

**点乘**

坐标意义上：点乘运算从坐标角度上是将两个向量进行逐x,逐y,逐z对应元素相乘后相加。在两个向量之间做运算，最后的结果是一个数值大小，该数值大小的反应了，两个运算向量（如果是单位向量）的方向相近程度。

几何意义上 a* b 的意义是，b 向量在 a 方向的投影长度。

**叉乘（右手坐标系是右手，左手坐标系是左手）**

坐标意义上：
$$
a 叉乘 b = (a_x,a_y,a_z ) 叉乘(b_x,b_y,b_z) = (a_yb_z - a_zb_y,a_zb_x - a_xb_z,a_xb_y-a_yb_x)
$$
如上所示，叉乘的运算是在两个向量中做运算最后的结果是一个向量，垂直于两个向量，叉乘可以判断两个向量的左右关系。叉乘的几何意义是可以通过右手定则来表示，a 叉乘 b 向量的结果是由四指指向a 向量转到b 向量。

**运算顺序**

平移 * 旋转 * 缩放

原向量当给定旋转角度的时候比如  我们的旋转矩阵需要遵循 z,x,y 的方向。

**旋转方式**

（1）欧拉角：定义了绕着三个坐标轴的旋转角，来确定刚体的旋转位置的方式，包括俯仰角pitch，偏航角yaw和滚动角roll；它的优点是比较直观，而且单个维度上的角度也比较容易插值；缺点是它不能进行任意方向的插值，而且会导致万向节死锁的问题，旋转的次序对结果也有影响

（2）矩阵：优点是不受万向节死锁的影响，可以独一无二的表达任意旋转，并且可以通过矩阵乘法来对点或矢量进行旋转变换；现在多数CPU以及所有GPU都有内置的硬件加速点积和矩阵乘法；缺点是不太直观，而且需要比较大的存储空间，也不太容易进行插值计算。

（3）四元数：四元数的好处是能够串接旋转；能把旋转直接作用于点或者矢量；而且能够进行旋转插值；另外它所占用的存储空间也比矩阵小；四元数可以解决万向节死锁的问题。

### 几何相关问题

**如何判断凹多边形还是凸多变形？**

* 相隔一点进行连线通过中间点在连线的内外判断是否是凸多边形还是凹多边形。
* 判断内角的角度，大于180 则为凹多边形。

**判断二维直线与三角形是否相交？**

* 将三角形三条边的方程写出，判断二维直线与三角形三条边的交点，根据交点的位置信息（通过其坐标），判断其是否交点在三角形边上

![be31f69b572d989f28dd7e80a5251f80](E:\WorkPr\知识点复习\复习内容\assets\be31f69b572d989f28dd7e80a5251f80.jpg)

**判断三维直线是否与三角形相交？**

* 先判断直线是否与三角形所在平面相交
* 如果相交求交点，将问题转化为，判断点是否在三角形内部

[直线是否过三角形](https://zhuanlan.zhihu.com/p/468132444?utm_id=0)    `

**三维直线与球相交**

part1:
$$
t^2 + 2t(d ⋅ (o − c)) + (o − c) ⋅ (o − c) − r^2 = 0
$$
将球体方程与三角形方程联立，解一个一元二次方程。看解 t 判断是否有交点。

part2:

使用点乘计算圆心连线到射线原点的连线，使用余弦定理求出半径，用半径去判断是否相交。

**三维直线与box相交**

平板法:

射线与三角形相交

## 局部光照模型

* **Lambrt 模型**

$$
LambertDiffuseColor = light.color * object.color * max(dot(wNormal,wLight),0)
$$

* **phong 模型**

$$
color_{1} = ambient_{2} + diffuse_{3} + specular_{4}
$$

$$
PhongSpecularColor = light.color * specular.color 
* (max(dot(refectLightDir,wViewDir),0))^p
$$

`V` 为观察者方向，`R` 为光线 `I` 关于法向量 `N` 的对称方向。

指数p的原因：防止反射光过大，离反射光越远就越不应该看见反射光，需要一个指数p加速衰减，如下图所示 指数p的作用：控制高光的大小，一般用100~200。

* **blinn phong 模型**

$$
PhongSpecularColor = light.color * specular.color 
* (max(dot(h,wNormal),0))^p
$$

![Image](https://pic4.zhimg.com/80/v2-764a5383c86ce91f6508514d6d3fc6b8.png)

## 全局光照（一般问的挺少的）

* SSAO

[SSAO HBAO等](https://www.bilibili.com/read/cv15211456/)

HBAO 对 SSAO 的正确性与性能都做了一些改进

* SSR 

屏幕空间反射

## 阴影

[Part1 实时阴影技术](https://zhuanlan.zhihu.com/p/640873640)

**shadowmap** [什么是ShadowMap](https://baijiahao.baidu.com/s?id=1762849907275369572&wfr=spider&for=pc)

让摄像机在光源位置处生成深度纹理图，在渲染中的将顶点位置变换到光源空间下，通过奠定的x,y 分量获取纹理上的深度值，如果阴影纹理中的深度信息小于顶点中的深度信息，那么就说明该点在阴影中。

**Screenspace Shadow Map屏幕空间阴影技术**

先得到光源阴影映射贴图，以及摄像机的深度纹理。然后根据这两者得到屏幕空间的阴影图，之后在全部的Shader 中做阴影图中的采样，然后判断（相机深度纹理中的值是否大于）就可以知道是否在在阴影中。

1. 从摄像机角度拍摄一张深度图，为cameraDepth
2. 从灯光角度拍摄一张深度图，为lightDepth
3. 将两个图blit，重建世界坐标点，转换到灯光空间，采样灯光空间的深度，比较，然后判断是否在阴影里，最后生成一个新的图，记作screenspaceShadowTex
4. 在绘制物体的时候，用物体的屏幕坐标uv，采样这个screenspaceShadowTex，乘以颜色即可。

**PCSS软阴影**

ShadowMapping过程中，对一个着色点的深度和阴影图的采样结果作比较，得到一个二元的结果即为在阴影中为1，不在阴影中为0。正因为这种二元性，才产生了硬阴影的没有过渡。而 PCF 是对像素周围的多个采样点进行插值和混合，从而更加准确地确定每个像素点的阴影强度。（Filtering的尺寸越大，得到的阴影越软，尺寸越小，得到的阴影越硬。但是Filtering尺寸越大，消耗也就越大）

PCSS 则是对 PCF 进行性能上的优化，，软阴影与硬阴影的之间的变化随着**阴影的投射物）与阴影的接受物的距离有关**。对于距离遮挡物较近的阴影选取较小的PCF核，对于较远者选取较大的PCF核。

选择策略为：

* 第一步：Blocker search，从shading point出发，连向light，比较shadow map，若在阴影里则是blocker，在一定区域内获取blocker的平均深度。
* 第二步：根据blocker的距离计算filter多大的范围（阴影软的程度）。
* 第三步：在该filter范围内做pcf。

**vssm（variance soft shadow mapping）**

本质上可以理解为是一种对pcss的加速，避免了第一步和第三步中的采样。用切比雪夫测试的方式直接判断当前深度在区域范围内排序的百分比，相当于我们就直接得到了visbility值，这样的做法避免了大量的采样，加速了整个过程。

**CSM**

Cascaded Shadow Maps(CSM)方法根据对象到观察者的距离提供不同分辨率的深度纹理来解决上述问题。它将相机的视锥体分割成若干部分，然后为分割的每一部分生成独立的深度贴图。对于近处的场景使用较高分辨率的阴影贴图，对于远处的场景使用粗糙的阴影贴图，在两张阴影贴图过渡的地方选择其中一张使用。

## 环境光照

[Part2 实时环境光照技术](https://zhuanlan.zhihu.com/p/652416647)]

### Cube Map

立方体贴图

### 反射探针

反射探针非常像一个捕捉周围各个方向的球形视图的摄像机。然后，捕捉的图像将存储为cubemap，可供具有反射材质的对象使用。

### IBL

对于渲染方程最简单来讲的话，物体发出的能量 = 其接受的光 乘 其BRDF + 自发光。

而其接受的光就是环境光照，IBL即使用基于图像的光照（Image Based Lighting，IBL）是基于立方体贴图技术改进的一种环境反射技术，它可以灵活控制反射属性，轻松模拟出物体材质光滑、粗糙等特性。（个人认为）IBL 不是一种基于物理的渲染方法，他只是将不同物体表面的光照信息描述出来。

我们使用 Cook-Torrance BRDF 的法线分布函数生成采样向量及其散射强度，该函数将法线和视角方向作为输入。由于我们在卷积环境贴图时事先不知道视角方向， 假设视角方向也就是镜面反射方向。所以对掠视角方向的效果不太好。

### 球谐光照

的本质是一系列的**定义在球面上的二维基函数** 三维空间的任何一个方向都是二维的。用一系列 SH 的组合，最后模拟出来的三维几何体去模拟`diffuse`的光照。

## 渲染方程

[计算机图形学笔记十三：Ray Tracing3（辐射度量学，渲染方程）_明川千美的博客-CSDN博客](https://blog.csdn.net/qq_51776686/article/details/122723818)
$$
L_o(p,\omega_o) = \int\limits_{\Omega} f_r(p,\omega_i,\omega_o) L_i(p,\omega_i) n \cdot \omega_i  d\omega_i
$$

`L` 计算的是在ω_o方向的眼睛观察到的 p 点的总辐照度。

f_r : 就是**双向反射分布函数**。

L_i : 是在 p 点接受到了全部辐射照度。

最后乘以的是入射角余弦

## PBR

[由浅入深学习PBR的原理和实现](https://www.cnblogs.com/timlly/p/10631718.html)

PBR光照模型需要满足：

- 基于微平面模型（Be based on the microfacet surface model）

认为在微观上所有材质表面都是由很多朝向不一的微小平面组成，有的材质表面光滑一些，有的粗糙一些。

- 能量守恒（Be energy conserving）

出射光的总能量不超过入射光的总能量（自发光材质除外）。即反射光越强，但整体亮度变暗。PBR是通过一Cook-Torrance BRDF 去实现近似的能量守恒。

Cook-Torrance BRDF分为漫反射和镜面反射两个部分，并且二者的系数和为1。

$$
f_r = k_d f_{lambert} +  k_s f_{cook-torrance}
$$

- 使用基于物理的BRDF（Use a physically based BRDF）

Cook-Torrance漫反射部分c代表的是Albedo或表面颜色，类似漫反射表面纹理。除以π是为了规格化漫反射光，为后期的BRDF积分做准备

Cook-Torrance镜面反射BRDF由3个函数（D，F，G）和一个标准化因子构成。D，F，G符号各自近似模拟了特定部分的表面反射属性：

- **D(Normal *D*istribution Function，NDF)**：法线分布函数，估算在受到表面粗糙度的影响下，取向方向与中间向量一致的微平面的数量。这是用来估算微平面的主要函数。
- **F(*F*resnel equation)**：菲涅尔方程，不同观察方向上，表面上被反射的光除以被折射的光的比例。
- **G(*G*eometry function)**：几何函数，描述了微平面自成阴影的属性。当一个平面相对比较粗糙的时候，平面表面上的微平面有可能挡住其他的微平面从而减少表面所反射的光线。

Ue4 中使用`SpitSum` 对参数进行了减少（减少了菲涅尔系数），并将粗糙度与视角防线夹角的预计算结果放在`LUT` 中。

**法线分布函数：**

与粗糙度`a` 和半角方向`h`相关，法线方向相关。

法线分布函数主要是影响高光的范围，尾长。

**几何函数**

与视角方向`v`和表面法项`n`还有粗糙度`a`相关

由于物体表面是粗糙的，与视角方向越垂直的方向，（在只考虑一次反射的基础上）反射光被其本身所的情况越大。所以会出现四周比中间暗的情况。（但是正因为被其本身吸收，所以会出现能量不守恒的情况，这部分能量需要我们在漫反射中补充）

**菲涅尔项**

与金属度`m`相关与`F0` 相关视角方向，。主要是和反射相关，比如看向水面时，看到其波光粼粼的表面。

## 抗锯齿

* MSAA

多重采样 MSAA（ Multi Sampling Anti-Aliasing）：把任何一个点/块都做一个平均，即对把像素分成更小的像素，每个小像素也有各自中心点，根据小像素在三角形内个数得到覆盖率，再通过覆盖率算出这个像素对应的颜色。 
MSAA实际上解决的是对图形进行模糊操作的这个过程，他只是通过近似的一种方法进行模糊，只是**增加采样点**并没有提高屏幕分辨率。

[延迟渲染与MSAA的更多细节可以参考这里](https://zhuanlan.zhihu.com/p/135444145)

* FXAA

快速近似抗锯齿 FXAA（Fast Approximate Anti-Aliasing），他是一种和采样无关，在图像层面做的处理，处理过程是先找到三角形的边界，把有锯齿的边界替换为没有锯齿的边界，而且处理起来非常快

[图形开发笔记 - 抗锯齿篇（2）FXAA Quality - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/640009907?utm_id=0)

* TAA

时间抗锯齿 TAA（Temporal Anti-Aliasing），最大的特点就是非常快速，是将静态的图片在时间上进行采样，图像不错MSAA，相连两帧显示的图像是一样，但是可以用相邻两帧同一个像素上不同位置的点来感知是否在三角形内，计算的时候要考虑上一帧感知的结果要被应用进来，相当于是MSAA对应的样本分布在时间上，并且当前这帧没有任何额外的操作

[有关TAA抗锯齿的简单介绍，在UE4中解决一些简单的抗锯齿问题 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/634654045?utm_id=0)

## 纹理

* 过滤方式：决定怎样将纹理像素映射到纹理坐标（怎样对纹理像素采样），分为临近过滤和线性过滤(采样)：

### minmap

提出背景：在一个场景内有很多物体，有的远有的近。远处的物体只占很少的片段（假设每个物体都有各自的纹理，且分辨率都很高的话），此时如果要从高分辨率的纹理中采样，会比较困难，因为一个很小的物体，一个像素映射到纹理上会占据很大一块，包含了很多个纹理像素，不好采样，因此引出了多级渐远纹理(mipmap)技术。

原理：将纹理划分为不同大小分辨率的纹理图集，每次缩小1/2划分，根据物体的大小，来对不同级别的纹理进行采样。对远处的物体，采用低分辨率的纹理，对于近处的物体，采用高分辨率的纹理：

#### 纹理优化手段

**CPU优化手段** - 降低DrawCall

- 纹理**图集**：一堆小纹理合成一个大的纹理（类似于原神场景LOD2与LOD3使用到的那种大图集）；
- 纹理**数组**（Texture Array）；
- 纹理**压缩**：降低纹理占的内存；

## 渲染方式

### 前向渲染

如果一个物体在多个光源的影响范围内，那要执行等同于光源数量的Pass，每个Pass 会对物体上的图元的每一个片元做光照计算。（N*M 的复杂度）在Unity 中的光照可以被设置为 重要和不重要两个模式，重要光照会做逐顶点运算，不重要的光照会使用SH进行合并计算。（球谐函数可以很好地表达低频信息，但是对于高频信息的还原不太好）

```C++
Pass {
    for (each primitive in this model) {
        for (each fragment covered by this primitive) {
            if(failed in depth test) {
                  discard; //没通过深度测试，则该片元不可见
            } else { //该片元可见，可继续进行光照计算
                float4 color = Shading(...);
               //更新帧缓冲，写入到颜色缓冲中
                writeFrameBuffer(fragment, color);
            }
        }
    }
}
```

### 延迟渲染

[延迟渲染的前世今生](https://zhuanlan.zhihu.com/p/28489928)

可以将延迟渲染(Deferred Rendering)理解为先将所有物体都先绘制到屏幕空间的缓冲（即G-buffer，Geometric Buffer，几何缓冲区）中，再逐光源对该缓冲进行着色的过程，从而避免了因计算被深度测试丢弃的⽚元的着色而产⽣的不必要的开销。也就是说延迟渲染基本思想是，先执行深度测试，再进行着色计算。

1. 几何处理阶段(Geometry Pass)。这个阶段中，我们获取对象的各种几何信息，并将第二步所需的各种数据储存（也就是渲染）到多个G-buffer中；

2. 光照处理阶段(Lighting Pass)。在这个pass中，我们只需渲染出一个屏幕大小的二维矩形，使用第一步在G-buffer中存储的数据对此矩阵的每一个片段计算场景的光照；光照计算的过程还是和正向渲染以前一样，只是现在我们需要从对应的G-buffer而不是顶点着色器(和一些uniform变量)那里获取输入变量了。

```C++
Many-light deferred shading algorithm
For each light:
    -Generate/bind shadow/environment maps
    -Compute light’s contribution for each G-buffer sample:
For each G-buffer sample
    -Load G-buffer data
    -Evaluate light contribution (may be zero)
    -Accumulate contribution into frame-buffer
```

一些要点：

- 内存开销较大。
- 读写G-buffer的内存带宽用量是性能瓶颈。
- 对透明物体的渲染存在问题。在这点上需要结合正向渲染进行渲染。
- 对多重采样抗锯齿（MultiSampling Anti-Aliasing, MSAA）的支持不友好，主要因为需开启MRT。

在每一帧当中G-buffer存储的信息有：<u>位置、法线、颜色值、镜面值</u>（<u>所以其实有三张纹理，分别存位置、法线和颜色+镜面值(RGB+)A</u>)；如果是PBR，应该还要再存一个金属度和粗糙度贴图。

也就是说，常见的两种Deferred Rendering的改进是：

- 延迟光照 Light Pre-Pass（即Deferred Lighting）
- 分块延迟渲染 Tile-BasedDeferred Rendering

**Light Pre-Pass**

- **几何阶段**：首先渲染场景的几何信息，包括位置、法线和材质属性，这些信息被储存在G-buffer中。不同于标准的延迟渲染（Deferred Rendering），Light Pre-Pass通常只存储几何和法线信息。
- **光照阶段**：接下来，使用上一步中的几何和法线信息来计算场景中每个像素的光照。这一步不直接计算最终的颜色，而是计算光照信息，如光强度和颜色。
- **组合阶段**：最后，结合第一阶段中的材质属性和第二阶段的光照信息来计算最终的像素颜色。

基于图块的渲染是现代 GPU 使用的一种技术，用于降低访问片外帧缓冲区内存的带宽要求。在外部内存访问成本高昂且渲染需求历来较低的移动领域几乎无处不在，桌面 GPU 现在也开始使用部分基于图块的渲染。

**Tile-BasedDeferred Rendering**

Vulkan 具有旨在充分利用基于图块的渲染器的特定功能，包括控制是否加载或清除以前的帧缓冲区内容、是否丢弃或写入附件内容以及控制附件解析和子通道。OpenGL ES 可以通过扩展实现类似的行为，但这些扩展并未得到普遍支持。为了从当前和未来的 GPU 中获得最佳性能，正确使用 API 以便高效地进行基于图块的渲染非常重要。

![img](https://pic2.zhimg.com/v2-4f8520cdcc9aa80ec2212ddbf918a231_r.jpg)

分块延迟渲染的主要思想则是把屏幕分拆成细小的栅格，例如每 32 × 32 象素作为一个分块（tile）。然后，计算每个分块会受到哪些光源影响，把那些光源的索引储存在分块的光源列表里。最后，逐个分块进行着色，对每像素读取 G-buffer 和光源列表及相关的光源信息。

因此，G-buffer的数据只会被读取1次且仅1次，写入 color buffer也是1次且仅1次，大幅降低内存带宽用量。不过，这种方法需要计算光源会影响哪些分块，这个计算又称为光源剔除（light culling），可以在 CPU 或 GPU（通常以 compute shader 实现）中进行。用GPU计算的好处是，GPU 计算这类工作比 CPU 更快，也减少 CPU／GPU 数据传输。而且，可以计算每个分块的深度范围（depth range），作更有效的剔除。

**G - buffer 的优化**

[G-buffer 内存优化](https://zhuanlan.zhihu.com/p/126345392)

## 杂项

### Z-Buffer算法

Z-Buffer的核心思想是对每个像素的z进行比较。 
Z-Buffer的算法步骤：

（1）Z-Buffer算法需要为每个像素点维持一个深度数组记为zbuffer，其每个位置初始值置为无穷大（即离摄像机无穷远）。

（2）随后我们遍历每个三角形面上的每一个像素点[x,y]，如果该像素点的深度值z，小于zbuffer[x,y]中的值，则更新zbuffer[x,y]值为该点深度值z，并同时更新该像素点[x,y]的颜色为该三角形面上的该点的颜色。

### Z-fighting

一个很常见的视觉错误会在两个平面或者三角形非常紧密地平行排列在一起时会发生，深度缓冲没有足够的精度来决定两个形状哪个在前面。结果就是这两个形状不断地在切换前后顺序，这会导致很奇怪的花纹。

第一个也是最重要的技巧是永远不要把多个物体摆得太靠近，以至于它们的一些三角形会重叠。通过在两个物体之间设置一个用户无法注意到的偏移值，你可以完全避免这两个物体之间的深度冲突。在箱子和地板的例子中，我们可以将箱子沿着正y轴稍微移动一点。箱子位置的这点微小改变将不太可能被注意到，但它能够完全减少深度冲突的发生。然而，这需要对每个物体都手动调整，并且需要进行彻底的测试来保证场景中没有物体会产生深度冲突。

第二个技巧是尽可能将近平面设置远一些。在前面我们提到了精度在靠近近平面时是非常高的，所以如果我们将近平面远离观察者，我们将会对整个平截头体有着更大的精度。然而，将近平面设置太远将会导致近处的物体被裁剪掉，所以这通常需要实验和微调来决定最适合你的场景的近平面距离。

另外一个很好的技巧是牺牲一些性能，使用更高精度的深度缓冲。大部分深度缓冲的精度都是24位的，但现在大部分的显卡都支持32位的深度缓冲，这将会极大地提高精度。所以，牺牲掉一些性能，你就能获得更高精度的深度测试，减少深度冲突。

### 从深度图中重建世界坐标

[深度重建世界坐标系的N种方法](https://zhuanlan.zhihu.com/p/654242431)

https://www.bilibili.com/video/BV1Bg4y1b7Sb/?spm_id_from=333.337.search-card.all.click

#### HDR

https://zhuanlan.zhihu.com/p/351666151

因为HDR图像的亮度范围已经超出了 [0, 1] 这个范围，显示器无法正确的显示HDR图像的颜色。因此我们需要将 HDR 图像数据映射到 [0, 1] 之间，这个过程就叫做色调映射（Tone Mapping）。经过色调映射后，HDR 图像数据能被显示器正确的显示，视觉效果也更加真实。

色调映射算法的本质是：用一个函数，将 [0, n] 的 HDR 数据映射到 [0, 1]。这个函数就是色调映射的算法。在游戏开发中色调映射算法有很多种，最简单的是 Reinhard tone mapping，最常用的有 Filmic tone mapping、ACES tone mapping。

Academy Color Encoding System（ACES）[[1\]](https://zhuanlan.zhihu.com/p/351666151#ref_1)是一个颜色空间规范，由美国电影艺术与科学学会设计的。 ACES Tone Mapping 是目前游戏开发领域最优秀的（表现力最好、性能也很好）色调映射算法，是现代游戏引擎中使用的最主流的色调映射算法。

### 广告牌

广告牌技术（billboarding）。广告牌技术会根据视角方向来旋转一个被纹理着色的多边形，使得多边形看起来好像总是正对着摄像机。广告牌可以被用于渲染火焰、烟雾、云朵或者闪光，在粒子效果中运用很广泛。

广告牌技术的本质就是构建旋转矩阵，构建一个旋转矩阵需要三个基向量。广告牌技术所使用的基向量通常就是表面法线（固定为视角方向）、指向上的方向以及向右的方向。除此之外一般还需要指定一个锚点(anchor location) ，这个锚点在旋转过程中是固定不变的，以此来确定多边形在空间中的位置。

### 实例化

实例化（gpu instance），这项技术能够让我们使用一个渲染调用来绘制多个物体，来节省每次绘制物体时CPU -> GPU的通信，它只需要一次即可。我们能够设置我们需要渲染的实例个数。这样我们只需要将必须的数据发送到GPU一次，然后使用一次函数调用告诉GPU它应该如何绘制这些实例。GPU将会直接渲染这些实例，而不用不断地与CPU进行通信。
